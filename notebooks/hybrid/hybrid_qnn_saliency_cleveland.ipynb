{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac395126-97a4-4d43-b7cc-7bf9948c802c",
   "metadata": {},
   "source": [
    "# üå∏ Hybrid Quantum‚ÄìClassical Neural Network on the Iris Dataset\n",
    "\n",
    "This notebook implements a **hybrid quantum-classical model** combining a **quantum neural network (QNN)** built with Qiskit and a classical neural layer in PyTorch.  \n",
    "The goal is to classify samples from the **Iris dataset** (4 features: sepal length/width, petal length/width; 3 classes: setosa, versicolor, virginica).\n",
    "\n",
    "### Why Hybrid?\n",
    "Hybrid QNNs leverage quantum circuits as **trainable feature extractors**, followed by classical layers for decision-making.  \n",
    "This allows exploration of near-term quantum computing while keeping classical efficiency.\n",
    "\n",
    "### üõ†Ô∏è Experimental Setup & Evaluation\n",
    "Before analysis, we:\n",
    "- Set up the environment (**PyTorch, Qiskit, scikit-learn, Matplotlib**).  \n",
    "- Preprocess the **Iris dataset** and prepare tensors for quantum encoding.  \n",
    "- Build **quantum circuits** for both plain and richer encoding schemes.  \n",
    "- Construct **QNNs** and integrate them into the hybrid model.  \n",
    "- Load **trained model weights** and **previously saved metrics**.  \n",
    "\n",
    "This setup enables all subsequent **evaluation and visualization**, including:  \n",
    "- Training performance (loss & accuracy)  \n",
    "- Test set evaluation (accuracy, confusion matrices, classification reports)  \n",
    "- Quantum layer outputs and embeddings  \n",
    "- Feature saliency and parameter sensitivity  \n",
    "- Statistical tests (Wilcoxon) to compare encodings\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öõÔ∏è Technologies Used\n",
    "\n",
    "- **Qiskit Machine Learning**: EstimatorV2, EstimatorQNN, TorchConnector  \n",
    "- **PyTorch**: neural network and optimizer  \n",
    "- **scikit-learn**: data handling, preprocessing, PCA  \n",
    "- **AerSimulator**: local quantum circuit simulation  \n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Outcome\n",
    "- Compare **plain vs richer encoding** performance  \n",
    "- Visualize **quantum embeddings** and **feature importance**  \n",
    "- Assess **parameter sensitivity** and **statistical significance** of differences  \n",
    "\n",
    "*Part of the QAMP Project: ‚ÄúQNNs ‚Äî Saliency & Sensitivity Kit‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0b0d6-d186-43ba-8f85-46b273b73729",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d7a81-06b0-4327-8119-6b356c69aa14",
   "metadata": {},
   "source": [
    "### üß© Data and PyTorch Setup\n",
    "\n",
    "In this section, we import the essential libraries required for data handling, preprocessing, and model training.  \n",
    "- **PyTorch** is used to define, train, and evaluate our hybrid neural network model.  \n",
    "- **scikit-learn** provides utilities for loading the **Iris dataset**, scaling features, and splitting data into training and testing sets.  \n",
    "- Additional tools such as **NumPy**, **Matplotlib**, and **SciPy** are used for numerical computation, visualization, and statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09336b1-7773-4081-a5ed-0d0cc3684ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. Core PyTorch modules =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Efficient batching & dataset handling\n",
    "\n",
    "# ===== 2. Machine Learning utilities (scikit-learn) =====\n",
    "from sklearn.datasets import load_iris                  # Classic Iris dataset (4 features, 3 classes)\n",
    "from sklearn.decomposition import PCA                   # Dimensionality reduction for visualization\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import train_test_split    # Train/test splitting\n",
    "from sklearn.preprocessing import StandardScaler        # Feature normalization\n",
    "\n",
    "# ===== 3. Statistical analysis =====\n",
    "from scipy.stats import wilcoxon                        # Non-parametric test (paired samples)\n",
    "\n",
    "# ===== 4. Visualization & numerics =====\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f75c0-d013-426a-aee2-c67b87abe2b2",
   "metadata": {},
   "source": [
    "### ‚öõÔ∏è Quantum Components (Qiskit Setup)\n",
    "Here we import Qiskit Machine Learning modules to build and simulate a quantum neural network (QNN).  \n",
    "We use `EstimatorV2` for evaluating circuits, `ParamShiftEstimatorGradient` for computing gradients,  \n",
    "and `TorchConnector` to integrate the quantum model with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd837e16-0607-453b-afd8-1f224ad5f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Qiskit Machine Learning components\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN  # Quantum neural network wrapper\n",
    "\n",
    "# Core Qiskit imports for building quantum circuits\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter  # Used to define trainable parameters (symbolic variables)\n",
    "\n",
    "# Import AerSimulator for local quantum circuit simulation\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "# Import EstimatorV2 (modern replacement for Estimator primitive) for circuit evaluation\n",
    "from qiskit_ibm_runtime import EstimatorV2\n",
    "\n",
    "# Connector to bridge Qiskit QNNs with PyTorch modules\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# SparsePauliOp defines quantum observables (like measuring Pauli Z)\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Gradient computation method using parameter-shift rule\n",
    "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f5e88",
   "metadata": {},
   "source": [
    "### üé≤ Reproducibility Setup\n",
    "\n",
    "To ensure consistent and comparable results across runs, we fix all random seeds used by **PyTorch** and **NumPy**.  \n",
    "This guarantees that data shuffling, weight initialization, and stochastic processes behave deterministically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b246b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1bd78",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Training Hyperparameters\n",
    "\n",
    "We define the key parameters that govern model training and encoding complexity.  \n",
    "These values control the learning process, dataset split, and model configuration for both plain and richer quantum encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1c7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Experiment Configuration =====\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 8\n",
    "QUBIT_COUNT = 8\n",
    "USE_RICHER_ENCODING = False      # Toggle Rz gates for richer encoding\n",
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 20\n",
    "LOG_INTERVAL = 1                # Set to None to disable logging\n",
    "UCI_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6940421",
   "metadata": {},
   "source": [
    "### üìÇ File Path Configuration\n",
    "\n",
    "All models and evaluation metrics are saved in dedicated directories for each encoding variant.  \n",
    "Separating these paths ensures clear experiment tracking and easy reproducibility when switching between configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33994a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== File Paths =====\n",
    "PLAIN_ENCODING_MODEL_PATH = \"../../models/hybrid/plain_encoding/hybrid_model_plain_encoding.pt\"\n",
    "RICH_ENCODING_MODEL_PATH  = \"../../models/hybrid/rich_encoding/hybrid_model_rich_encoding.pt\"\n",
    "\n",
    "PLAIN_ENCODING_METRICS_PATH = \"../../metrics/hybrid/plain_encoding/metrics_plain_encoding\"\n",
    "RICH_ENCODING_METRICS_PATH  = \"../../metrics/hybrid/rich_encoding/metrics_rich_encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090a5ac-8c3b-4ce2-a66d-aa7acf9fe1ac",
   "metadata": {},
   "source": [
    "## üå∏ Data Preprocessing ‚Äî Iris Dataset\n",
    "\n",
    "In this section, we load and preprocess the **Iris dataset** to make it compatible with our hybrid quantum-classical neural network.\n",
    "\n",
    "- The dataset contains **4 numerical features** per sample:  \n",
    "  *sepal length*, *sepal width*, *petal length*, and *petal width* ‚Äî  \n",
    "  describing the physical characteristics of iris flowers.\n",
    "\n",
    "- The **target labels** represent **three iris species** (*setosa*, *versicolor*, *virginica*).\n",
    "\n",
    "We apply the following preprocessing steps:\n",
    "1. **Normalization** ‚Äî features are standardized using `StandardScaler` to have zero mean and unit variance.  \n",
    "2. **Quantum Rescaling** ‚Äî the standardized features are mapped to the range `[0, œÄ]`, aligning with the input domain of quantum rotation gates.  \n",
    "3. **Data Splitting** ‚Äî the dataset is divided into training and testing sets using an 80/20 ratio.  \n",
    "4. **Tensor Conversion** ‚Äî all arrays are converted into PyTorch tensors for seamless integration with the model.  \n",
    "5. **Batch Loading** ‚Äî training data is wrapped into a `DataLoader` for efficient mini-batch processing and shuffling during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7962ecb-09c0-4e4d-812b-8c800e3eca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features: ['thal', 'cp', 'ca', 'exang', 'oldpeak', 'chol', 'thalach', 'slope']\n",
      "Data shape: (303, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- ASSUMED CONSTANTS ---\n",
    "# Ensure QUBIT_COUNT is 8 here to match the 8 features\n",
    "# QUBIT_COUNT = 8 \n",
    "# UCI_URL, UCI_COLS, CSV_PATH, TEST_SIZE, BATCH_SIZE must be defined previously.\n",
    "\n",
    "# The list of the top 8 features identified from the first notebook\n",
    "TOP_8_FEATS = ['thal', 'cp', 'ca', 'exang', 'oldpeak', 'chol', 'thalach', 'slope']\n",
    "UCI_COLS = [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"]\n",
    "CSV_PATH = None\n",
    "\n",
    "# Load UCI dataset\n",
    "def load_cleveland_uci(csv_path: str | None, url_fallback: str):\n",
    "    df = pd.read_csv(csv_path or url_fallback, header=None, names=UCI_COLS, na_values=\"?\")\n",
    "    y = (df[\"num\"].astype(float) > 0).astype(int).to_numpy()\n",
    "    \n",
    "    # FIX: Hardcode the TOP_8_FEATS list for selection\n",
    "    X_df = df[TOP_8_FEATS].apply(pd.to_numeric, errors=\"coerce\")  \n",
    "    \n",
    "    X_num = SimpleImputer(strategy=\"median\").fit_transform(X_df)\n",
    "    feature_cols = X_df.columns.tolist()\n",
    "    return X_num.astype(np.float64), y.astype(int), feature_cols\n",
    "\n",
    "# Load dataset\n",
    "X, y, feature_cols = load_cleveland_uci(CSV_PATH, UCI_URL)\n",
    "print(f\"Loaded features: {feature_cols}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Scale to [0, pi] range for quantum encoding\n",
    "X_scaled = np.pi * (X_scaled / (np.max(np.abs(X_scaled), axis=0, keepdims=True) + 1e-9))\n",
    "\n",
    "# Train/test split (using TEST_SIZE from your config)\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
    "    X_scaled, y, test_size=TEST_SIZE, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "# NOTE: Labels should be float for BCEWithLogitsLoss\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1) \n",
    "y_test = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3b6ea-d97b-441e-96e7-573e84c88761",
   "metadata": {},
   "source": [
    "## ‚öõÔ∏è Quantum Circuit Construction\n",
    "\n",
    "This section defines the **parameterized quantum circuit (PQC)** that forms the quantum core of the hybrid model.  \n",
    "The circuit encodes classical data into qubit states and applies trainable rotations and entanglement to learn complex feature relationships.\n",
    "\n",
    "### üß† Circuit Structure\n",
    "- **Qubits:**  \n",
    "  One qubit per input feature (4 in total for the Iris dataset).  \n",
    "- **Classical Encoding Parameters (`x_params`):**  \n",
    "  Classical features are embedded into qubit rotations using the `RY` gate, and optionally also `RZ` gates when *richer encoding* is enabled.  \n",
    "  - `RY(x·µ¢)` encodes each feature as a rotation around the Y-axis.  \n",
    "  - `RZ(x·µ¢)` (optional) adds rotation around the Z-axis for greater expressive power.  \n",
    "- **Trainable Parameters (`theta_params`):**  \n",
    "  These represent learnable weights in the quantum layers.  \n",
    "  Two variational layers are included, each with rotations `RY(Œ∏)` and **CNOT entanglement** between adjacent qubits.\n",
    "\n",
    "### üîó Circuit Workflow\n",
    "1. **Encoding Layer:**  \n",
    "   Classical input features are encoded as quantum rotations (`RY` + optional `RZ`).\n",
    "2. **Variational Layer 1:**  \n",
    "   First set of trainable `RY` rotations followed by linear entanglement via `CX` gates.\n",
    "3. **Variational Layer 2:**  \n",
    "   Second set of trainable rotations and entanglement, allowing non-linear feature mixing.\n",
    "4. **Measurement:**  \n",
    "   Each qubit is measured using a Pauli-Z observable, producing expectation values as the quantum layer‚Äôs output vector.\n",
    "\n",
    "This design enables a balance between **expressivity** (via richer encoding) and **trainability** (via limited parameter count), making it suitable for small datasets like Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c09c61-27b7-4b53-8fbc-40b9571ebb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_quantum_circuit(use_richer_encoding=True):\n",
    "    qc = QuantumCircuit(QUBIT_COUNT)\n",
    "\n",
    "    # Parameters used for encoding classical features into qubits\n",
    "    x_params = [Parameter(f'x{i}') for i in range(QUBIT_COUNT)]\n",
    "\n",
    "    # Trainable parameters for the variational layers (two layers)\n",
    "    theta_params = [Parameter(f'theta{i}_1') for i in range(QUBIT_COUNT)] + \\\n",
    "                   [Parameter(f'theta{i}_2') for i in range(QUBIT_COUNT)]\n",
    "\n",
    "    # Layer 1: Input encoding + variational\n",
    "    for i in range(QUBIT_COUNT):\n",
    "        qc.ry(x_params[i], i)      # Encode feature i as rotation around Y-axis\n",
    "        if use_richer_encoding:\n",
    "            qc.rz(x_params[i], i)  # Encode feature i as rotation around Z-axis for richer representation\n",
    "\n",
    "    for i in range(QUBIT_COUNT):\n",
    "        qc.ry(theta_params[i], i)  # First layer of trainable rotations\n",
    "\n",
    "    for i in range(QUBIT_COUNT - 1):\n",
    "        qc.cx(i, i + 1)            # Linear entanglement between qubits with CNOT gates\n",
    "\n",
    "    # Layer 2: Variational only\n",
    "    for i in range(QUBIT_COUNT, 2 * QUBIT_COUNT):\n",
    "        qc.ry(theta_params[i], i - QUBIT_COUNT)  # Second layer of trainable rotations\n",
    "    for i in range(QUBIT_COUNT - 1):\n",
    "        qc.cx(i, i + 1)                          # Another layer of linear entanglement\n",
    "\n",
    "    # Measure the Pauli-Z operator on each qubit\n",
    "    # This provides a vector of expectation values (one per qubit) as the quantum output\n",
    "    observables = [SparsePauliOp(\"I\" * (QUBIT_COUNT - 1) + \"Z\")]\n",
    "    \n",
    "    return qc, x_params, theta_params, observables\n",
    "\n",
    "qc, x_params, theta_params, observables = build_quantum_circuit(use_richer_encoding=USE_RICHER_ENCODING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77988d",
   "metadata": {},
   "source": [
    "### üìü Quantum Circuit Visualization\n",
    "\n",
    "Below is the schematic representation of the parameterized quantum circuit (PQC) built in the previous step.  \n",
    "It shows the data encoding rotations (`RY`, optionally `RZ`), trainable variational layers, and entanglement (`CX`) structure across all qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48997c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1123.61x702.333 with 1 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad53c1",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Quantum Neural Network (QNN) Construction\n",
    "\n",
    "In this step, we transform the parameterized quantum circuit (PQC) into a **trainable quantum neural network** that can interface with PyTorch.\n",
    "\n",
    "### üîπ Key Components\n",
    "- **Backend Simulator:**  \n",
    "  We use `AerSimulator` with the **statevector method** to simulate the quantum circuit on a classical machine.\n",
    "- **Estimator:**  \n",
    "  `EstimatorV2` evaluates expectation values of the specified observables for given input and trainable parameters.\n",
    "- **Gradient Computation:**  \n",
    "  The **parameter-shift rule** is used to compute gradients for all trainable parameters:\n",
    "  - For each parameter Œ∏, evaluate the circuit twice: Œ∏ + œÄ/2 and Œ∏ ‚àí œÄ/2.\n",
    "  - The difference gives the gradient w.r.t. that parameter.\n",
    "- **EstimatorQNN:**  \n",
    "  Combines the circuit, estimator, input parameters, weight parameters, and observables into a QNN object.\n",
    "- **TorchConnector:**  \n",
    "  Bridges the QNN with PyTorch, allowing seamless integration of the quantum layer into a hybrid classical-quantum model.\n",
    "\n",
    "### ‚ö° Output\n",
    "- `qnn`: The QNN object for quantum computations and gradient evaluation.\n",
    "- `qnn_torch`: A PyTorch-compatible module that can be used as a layer in the hybrid neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ec3cfb-04f1-4266-9456-ac2097233702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qnn(qc, x_params, theta_params, observables):\n",
    "    backend = AerSimulator(method='statevector')  # Quantum simulator backend\n",
    "    estimator = EstimatorV2(mode=backend)         # Evaluates circuit expectation values\n",
    "\n",
    "    # Gradient computation using the parameter-shift rule\n",
    "    # For each trainable parameter, the circuit is evaluated twice:\n",
    "    # once with the parameter shifted +pi/2, once with -pi/2, then the difference gives the gradient\n",
    "    gradient = ParamShiftEstimatorGradient(estimator)\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=estimator,\n",
    "        input_params=x_params,\n",
    "        weight_params=theta_params,\n",
    "        observables=observables,\n",
    "        gradient=gradient\n",
    "    )\n",
    "\n",
    "    qnn_torch = TorchConnector(qnn)  # Link the QNN with PyTorch for hybrid training\n",
    "    return qnn, qnn_torch\n",
    "\n",
    "qnn, qnn_torch = build_qnn(qc, x_params, theta_params, observables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432fda6",
   "metadata": {},
   "source": [
    "## üß¨ Hybrid Quantum-Classical Model\n",
    "\n",
    "In this section, we define a **hybrid neural network** that combines the **quantum layer** with classical fully connected layers.\n",
    "\n",
    "### üîπ Model Architecture\n",
    "1. **Quantum Layer (`qlayer`)**  \n",
    "   - Takes classical input features and outputs **expectation values** from the QNN.  \n",
    "   - Acts as the first layer in the hybrid model, providing a rich, non-linear quantum embedding of the data.\n",
    "\n",
    "2. **Classical Hidden Layer (`hidden`)**  \n",
    "   - Fully connected layer mapping the quantum outputs to a higher-dimensional space (6 neurons).  \n",
    "   - Uses **ReLU activation** to introduce non-linearity.\n",
    "\n",
    "3. **Output Layer (`fc`)**  \n",
    "   - Fully connected layer mapping the hidden representation to **3 output logits** corresponding to the Iris species.  \n",
    "\n",
    "### ‚ö° Training Setup\n",
    "- **Loss Function:** Cross-entropy loss for multi-class classification.  \n",
    "- **Optimizer:** Adam optimizer with learning rate defined by `LEARNING_RATE`.  \n",
    "- **Integration:** The quantum layer is passed into the model during initialization, allowing end-to-end hybrid training with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38afec46-ff6f-4b1a-9c74-dc8492d405fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, qlayer):\n",
    "        super().__init__()\n",
    "        self.qlayer = qlayer\n",
    "        \n",
    "        # New: Input size must be 1 if observables is a single item (a scalar)\n",
    "        self.hidden = nn.Linear(1, 8) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(8, 1)\n",
    "\n",
    "        # Initialize weights\n",
    "        torch.nn.init.uniform_(self.hidden.weight, -0.1, 0.1)\n",
    "        torch.nn.init.uniform_(self.fc.weight, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, 4) -> qlayer(x) shape (batch, 1)\n",
    "        x = self.qlayer(x) \n",
    "        \n",
    "        # Ensure x is 2D: (batch, 1)\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1) \n",
    "            \n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = HybridModel(qlayer=qnn_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8677df-dbf9-4fce-b048-fb7c860f866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80edf4b",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training the Hybrid Model\n",
    "\n",
    "We train the hybrid quantum-classical model using mini-batch gradient descent with the **Adam optimizer** and **cross-entropy loss**.  \n",
    "\n",
    "### üîπ Training Procedure\n",
    "1. Iterate over **`EPOCHS`**. For each epoch:\n",
    "   - Initialize epoch loss and correct prediction counters.\n",
    "2. Loop over **mini-batches** from the `DataLoader`:\n",
    "   - Reset gradients (`optimizer.zero_grad()`).\n",
    "   - Forward pass through the hybrid model (`model(batch_x)`).\n",
    "   - Compute batch loss and backpropagate (`loss.backward()`).\n",
    "   - Update model parameters (`optimizer.step()`).\n",
    "3. Track metrics:\n",
    "   - **Epoch Loss:** average weighted loss over all training samples.  \n",
    "   - **Epoch Accuracy:** proportion of correctly classified samples.\n",
    "4. Log metrics every `LOG_INTERVAL` epochs.\n",
    "\n",
    "This loop allows **end-to-end training** of both the quantum and classical components of the hybrid network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490e5ded-2e3b-40ae-9258-c370f920070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.6946, Train Accuracy=0.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.6869, Train Accuracy=0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6770, Train Accuracy=0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6567, Train Accuracy=0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.6138, Train Accuracy=0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.5852, Train Accuracy=0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.5706, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.5572, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.5476, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.5367, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.5341, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.5269, Train Accuracy=0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.5227, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.5203, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.5154, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.5170, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.5107, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.5120, Train Accuracy=0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.5079, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.5101, Train Accuracy=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    for batch_x, batch_y in loop:\n",
    "        batch_x = batch_x.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(batch_x)         # shape: (batch, 1)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "        # ---- FIX 2: Binary predictions using sigmoid ----\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        total += batch_x.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=epoch_loss / total, acc=correct / total)\n",
    "\n",
    "    epoch_loss /= total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    if LOG_INTERVAL is not None and (epoch + 1) % LOG_INTERVAL == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss={epoch_loss:.4f}, Train Accuracy={epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77bead",
   "metadata": {},
   "source": [
    "### üíæ Saving Trained Model and Metrics\n",
    "\n",
    "After training, we save the **hybrid model parameters** and **training metrics** for future evaluation or reuse, based on the chosen encoding.\n",
    "\n",
    "### ‚ö° Saving Procedure\n",
    "1. **Model Weights:** saved with `torch.save(model.state_dict(), model_path)`.  \n",
    "2. **Training Metrics:** loss and accuracy per epoch saved with `np.save(metrics_path, [train_losses, train_accuracies])`.\n",
    "\n",
    "This ensures **experiment reproducibility** and allows later comparison between plain and richer encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72cda87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_RICHER_ENCODING:\n",
    "    model_path = RICH_ENCODING_MODEL_PATH\n",
    "    metrics_path = RICH_ENCODING_METRICS_PATH\n",
    "else:\n",
    "    model_path = PLAIN_ENCODING_MODEL_PATH\n",
    "    metrics_path = PLAIN_ENCODING_METRICS_PATH\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "np.save(metrics_path, [train_losses, train_accuracies])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429a14c",
   "metadata": {},
   "source": [
    "## üß™ Model Evaluation & Visualization\n",
    "\n",
    "In this section, we first **set up the evaluation environment** by loading the trained hybrid quantum-classical models (plain and richer encoding) and retrieving the previously saved **training metrics** (losses and accuracies).  \n",
    "\n",
    "With the models and metrics ready, we perform a comprehensive evaluation and visualization.\n",
    "\n",
    "### ‚ö° What We Do Here\n",
    "- **Setup & Retrieval:**  \n",
    "  - Load both hybrid models using `load_hybrid_model`.  \n",
    "  - Organize them in a dictionary for easy iteration.  \n",
    "  - Load saved training metrics (losses and accuracies) for plotting and comparison.\n",
    "\n",
    "- **Training Performance:**  \n",
    "  - Plot **loss and accuracy curves** for plain vs richer encoding.\n",
    "\n",
    "- **Test Set Evaluation:**  \n",
    "  - Compute test accuracy, **confusion matrices**, and **classification reports**.\n",
    "\n",
    "- **Model Internals Visualization:**  \n",
    "  - Inspect **quantum layer outputs**.  \n",
    "  - Compute and visualize **feature saliency maps**.  \n",
    "  - Analyze **latent embeddings** via PCA.\n",
    "\n",
    "- **Parameter Sensitivity:**  \n",
    "  - Examine gradients of trainable parameters to assess their influence on predictions.\n",
    " \n",
    "* **Explainability & Interpretability Metrics:**\n",
    "\n",
    "  * **Feature Saliency / Average Feature Sensitivity** ‚Üí highlights which input features most influence model outputs.\n",
    "  * **Sparseness (L1/L2 ratio)** ‚Üí quantifies how concentrated or diffuse the saliency map is.\n",
    "  * **Saliency Entropy** ‚Üí measures how spread out the saliency values are across features.\n",
    "  * **Deletion Metric / Fidelity** ‚Üí tests if removing top-salient features reduces true-class probability.\n",
    "  * **Bug / Overreliance Detection** ‚Üí compares saliency for correct vs incorrect predictions to detect misalignment or potential model bias.\n",
    "  * **Minimum Efficacy** ‚Üí evaluates if saliency provides information beyond raw model confidence.\n",
    "  * **Overreliance Risk** ‚Üí correlation between confidence and fidelity to check if explanations could mislead humans by overstating certainty.\n",
    "\n",
    "- **Statistical Testing:**  \n",
    "  - Use the **Wilcoxon signed-rank test** to quantify differences in feature importance between plain and richer encoding.\n",
    " \n",
    "### ‚ö†Ô∏è Note on Classical vs Quantum Metrics\n",
    "\n",
    "Most of the metrics above are **classical interpretability metrics**, widely established in XAI literature.\n",
    "\n",
    "* This is because **quantum-specific explainability metrics are still scarce**, and the field lacks standardized methods for analyzing hybrid quantum-classical models.\n",
    "* Using classical metrics allows us to **evaluate and compare the hybrid models in a rigorous and interpretable way**, even though part of the model is quantum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92d2d47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for HybridModel:\n\tsize mismatch for qlayer.weight: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for qlayer._weights: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for hidden.weight: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for hidden.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 6]) from checkpoint, the shape in current model is torch.Size([1, 8]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Load trained hybrid models for both encoding types\u001b[39;00m\n\u001b[32m     24\u001b[39m model_plain = load_hybrid_model(\u001b[38;5;28;01mFalse\u001b[39;00m, PLAIN_ENCODING_MODEL_PATH)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m model_rich  = \u001b[43mload_hybrid_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRICH_ENCODING_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Organize models in a dictionary for convenience\u001b[39;00m\n\u001b[32m     28\u001b[39m models = {\u001b[33m\"\u001b[39m\u001b[33mPlain Encoding\u001b[39m\u001b[33m\"\u001b[39m: model_plain, \u001b[33m\"\u001b[39m\u001b[33mRicher Encoding\u001b[39m\u001b[33m\"\u001b[39m: model_rich}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mload_hybrid_model\u001b[39m\u001b[34m(richer_encoding, saved_model_path)\u001b[39m\n\u001b[32m     13\u001b[39m model = HybridModel(qnn_torch)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Load saved weights\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m model.eval()\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Restore the original flag\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for HybridModel:\n\tsize mismatch for qlayer.weight: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for qlayer._weights: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for hidden.weight: copying a param with shape torch.Size([6, 4]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for hidden.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 6]) from checkpoint, the shape in current model is torch.Size([1, 8]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "def load_hybrid_model(richer_encoding: bool, saved_model_path: str):\n",
    "    global USE_RICHER_ENCODING\n",
    "    original_flag = USE_RICHER_ENCODING\n",
    "    USE_RICHER_ENCODING = richer_encoding\n",
    "\n",
    "    # Build quantum circuit\n",
    "    qc, x_params, theta_params, observables = build_quantum_circuit(use_richer_encoding=USE_RICHER_ENCODING)\n",
    "\n",
    "    # Build QNN and Torch connector\n",
    "    _, qnn_torch = build_qnn(qc, x_params, theta_params, observables)\n",
    "\n",
    "    # Create model and attach the quantum layer\n",
    "    model = HybridModel(qnn_torch)\n",
    "\n",
    "    # Load saved weights\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # Restore the original flag\n",
    "    USE_RICHER_ENCODING = original_flag\n",
    "    return model\n",
    "\n",
    "# Load trained hybrid models for both encoding types\n",
    "model_plain = load_hybrid_model(False, PLAIN_ENCODING_MODEL_PATH)\n",
    "model_rich  = load_hybrid_model(True, RICH_ENCODING_MODEL_PATH)\n",
    "\n",
    "# Organize models in a dictionary for convenience\n",
    "models = {\"Plain Encoding\": model_plain, \"Richer Encoding\": model_rich}\n",
    "\n",
    "# Load previously saved training metrics (losses and accuracies)\n",
    "plain_losses, plain_acc = np.load(PLAIN_ENCODING_METRICS_PATH + \".npy\", allow_pickle=True)\n",
    "rich_losses, rich_acc   = np.load(RICH_ENCODING_METRICS_PATH + \".npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20368cdd",
   "metadata": {},
   "source": [
    "### üìà Training Loss and Accuracy Comparison\n",
    "\n",
    "This plot shows the **training performance** of the hybrid models for both **plain** and **richer encoding** schemes.\n",
    "\n",
    "- **Left Plot ‚Äî Training Loss:**  \n",
    "  Visualizes how the cross-entropy loss decreases over epochs for each model. Lower values indicate better learning.\n",
    "\n",
    "- **Right Plot ‚Äî Training Accuracy:**  \n",
    "  Shows the proportion of correctly classified training samples per epoch. Higher values indicate better model performance.\n",
    "\n",
    "By comparing these curves, we can see the **impact of richer encoding** on learning speed and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "# Training Loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(plain_losses, label=\"Plain Encoding\")\n",
    "plt.plot(rich_losses, label=\"Richer Encoding\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "\n",
    "# Training Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(plain_acc, label=\"Plain Encoding\")\n",
    "plt.plot(rich_acc, label=\"Richer Encoding\")\n",
    "plt.title(\"Training Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1016ab",
   "metadata": {},
   "source": [
    "### üß© Test Accuracy and Confusion Matrices\n",
    "\n",
    "In this section, we **evaluate the trained hybrid models** on the test set and visualize their performance.\n",
    "\n",
    "- **Test Accuracy:**  \n",
    "  Prints the overall accuracy for each model (plain vs richer encoding).\n",
    "\n",
    "- **Confusion Matrices:**  \n",
    "  Show how well each model predicts each Iris species.  \n",
    "  - Diagonal values: correctly classified samples  \n",
    "  - Off-diagonal values: misclassifications  \n",
    "\n",
    "This visualization allows quick comparison of **classification strengths and weaknesses** between the two encoding approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "for i, (name, mdl) in enumerate(models.items()):\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        outputs = mdl(X_test)                 # Forward pass on test set\n",
    "        _, preds = torch.max(outputs, 1)      # Get predicted class labels\n",
    "        test_acc = (preds == y_test).float().mean().item()  # Compute test accuracy\n",
    "        print(f\"{name} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        # Compute and display the confusion matrix\n",
    "        cm = confusion_matrix(y_test.numpy(), preds.numpy())\n",
    "        plt.subplot(1, 2, i+1)  # Place the plot in the correct subplot\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "        disp.plot(cmap=plt.cm.Blues, ax=plt.gca(), colorbar=False)  # Draw the confusion matrix\n",
    "        plt.title(f\"{name} Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eb111",
   "metadata": {},
   "source": [
    "### üìä Classification Reports\n",
    "\n",
    "This section provides **detailed evaluation metrics** for each model on the test set:\n",
    "\n",
    "- **Precision:** proportion of correct positive predictions per class.  \n",
    "- **Recall:** proportion of actual positives correctly identified per class.  \n",
    "- **F1-score:** harmonic mean of precision and recall.  \n",
    "- **Support:** number of samples for each class.  \n",
    "\n",
    "Comparing the reports for **plain vs richer encoding** helps identify which Iris species each model classifies better or struggles with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, mdl in models.items():\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        outputs = mdl(X_test)                 # Forward pass on test set\n",
    "        _, preds = torch.max(outputs, 1)      # Get predicted class labels\n",
    "    \n",
    "    # Print detailed classification metrics\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_test,                               # True labels\n",
    "        preds,                                # Predicted labels\n",
    "        target_names=iris.target_names        # Human-readable class names\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe8a45",
   "metadata": {},
   "source": [
    "### ‚öõÔ∏è Quantum Layer Outputs\n",
    "\n",
    "This section visualizes the **expectation values from the quantum layer** for each test sample:\n",
    "\n",
    "- **Heatmap:** each row corresponds to a test sample, each column to a qubit.  \n",
    "- **Color intensity:** represents the magnitude of the quantum expectation value.  \n",
    "\n",
    "Comparing the heatmaps for **plain vs richer encoding** gives insight into how the encoding strategy affects the quantum feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf6a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "for i, (name, mdl) in enumerate(models.items()):\n",
    "    # Get the output of the quantum layer (expectation values) for all test samples\n",
    "    q_outputs = qnn_torch(X_test).detach().numpy()\n",
    "    \n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(\n",
    "        q_outputs,\n",
    "        cmap='viridis',\n",
    "        aspect='auto',\n",
    "        extent=[0, q_outputs.shape[1]-1, 0, q_outputs.shape[0]-1]  # qubits on x, samples on y\n",
    "    )\n",
    "    plt.colorbar(label=\"Quantum Expectation Value\")\n",
    "    plt.title(f\"{name} Quantum Layer Outputs\")\n",
    "    plt.xlabel(\"Qubits\")\n",
    "    plt.ylabel(\"Samples\")\n",
    "    plt.gca().invert_yaxis()  # optional: have first sample at the top\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf3c46",
   "metadata": {},
   "source": [
    "### üîç Feature Saliency Analysis\n",
    "\n",
    "This section analyzes **how sensitive the model outputs are to each input feature**:\n",
    "\n",
    "- **Saliency Maps:**  \n",
    "  - Computed using a finite difference method: perturb each feature slightly and observe the change in output.  \n",
    "  - Rows = test samples, columns = features.  \n",
    "  - Color intensity indicates how strongly the model output responds to that feature.\n",
    "\n",
    "- **Average Feature Saliency:**  \n",
    "  - Aggregates the saliency values across all samples for each feature.  \n",
    "  - Bar plots allow direct comparison of **plain vs richer encoding** models.  \n",
    "\n",
    "Insights:  \n",
    "- Features with higher saliency are more important for the model‚Äôs decision.  \n",
    "- Differences between plain and richer encoding indicate how the extra RZ rotations influence feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0949bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency(model, inputs, delta=1e-3):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    inputs = inputs.clone().detach()  # Avoid modifying original data\n",
    "    base_output = model(inputs).detach().numpy()  # Base model output\n",
    "    saliency = np.zeros_like(inputs)  # Initialize saliency array\n",
    "\n",
    "    for feature_idx in range(inputs.shape[1]):\n",
    "        # Perturb one feature at a time\n",
    "        perturbed = inputs.clone()\n",
    "        perturbed[:, feature_idx] += delta\n",
    "        \n",
    "        # Compute model output for perturbed input\n",
    "        perturbed_output = model(perturbed).detach().numpy()\n",
    "        \n",
    "        # Estimate gradient via finite difference\n",
    "        grad_estimate = (perturbed_output - base_output) / delta\n",
    "        \n",
    "        # Aggregate absolute gradient across output dimensions\n",
    "        saliency[:, feature_idx] = np.mean(np.abs(grad_estimate), axis=1)\n",
    "    \n",
    "    return saliency\n",
    "\n",
    "# Compute saliency maps for both models\n",
    "saliency_plain = compute_saliency(model_plain, X_test)\n",
    "saliency_rich  = compute_saliency(model_rich, X_test)\n",
    "\n",
    "# ----- Plot saliency maps side-by-side -----\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(saliency_plain, cmap='hot', aspect='auto')\n",
    "plt.colorbar(label=\"Feature Sensitivity\")\n",
    "plt.title(\"Saliency Map: Plain Encoding\")\n",
    "plt.xticks(range(X_test.shape[1]), iris.feature_names, rotation=45)\n",
    "plt.ylabel(\"Samples\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(saliency_rich, cmap='hot', aspect='auto')\n",
    "plt.colorbar(label=\"Feature Sensitivity\")\n",
    "plt.title(\"Saliency Map: Richer Encoding\")\n",
    "plt.xticks(range(X_test.shape[1]), iris.feature_names, rotation=45)\n",
    "plt.ylabel(\"Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----- Average feature saliency comparison -----\n",
    "mean_plain = saliency_plain.mean(axis=0)\n",
    "mean_rich  = saliency_rich.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "x = np.arange(len(iris.feature_names))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, mean_plain, width, label=\"Plain\")\n",
    "plt.bar(x + width/2, mean_rich, width, label=\"Richer\")\n",
    "plt.xticks(x, iris.feature_names, rotation=45)\n",
    "plt.ylabel(\"Average Saliency\")\n",
    "plt.title(\"Average Feature Sensitivity Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f442d3-3fa4-4d8c-98dd-039753441279",
   "metadata": {},
   "source": [
    "### üß™ Average Sensitivity (Stability of Explanations)\n",
    "\n",
    "This section evaluates **how stable the model‚Äôs saliency explanations are** under small perturbations of the input.\n",
    "\n",
    "* **Purpose:**\n",
    "  Average Sensitivity measures whether tiny random changes to the input cause large changes in the saliency values.\n",
    "  A good explanation method should be **stable** e.g. small input noise should not radically alter which features appear important.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute the original saliency map for the model.\n",
    "  2. Add a very small random perturbation (Gaussian noise scaled by `Œ¥`) to each input sample.\n",
    "  3. Recompute the saliency on the perturbed input.\n",
    "  4. Measure the **mean absolute difference** between the two saliency maps.\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * **Low Average Sensitivity** -> robust, stable explanations.\n",
    "  * **High Average Sensitivity** -> explanations are fragile and inconsistent.\n",
    "  * Comparing values for **plain** vs **richer encoding** reveals whether the richer architecture produces more reliable feature attributions.\n",
    "\n",
    "This metric helps ensure that saliency-based explanations are not just accurate but also **consistent**, which is critical for human trust and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44297f3e-227a-4649-a0fa-51465bdb4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sensitivity(model, inputs, delta=1e-3, saliency_fn=compute_saliency):\n",
    "    # Original saliency\n",
    "    saliency_orig = saliency_fn(model, inputs, delta)\n",
    "    \n",
    "    # Add small random noise to inputs\n",
    "    noise = torch.randn_like(inputs) * delta\n",
    "    inputs_perturbed = inputs + noise\n",
    "    \n",
    "    # Saliency for perturbed inputs\n",
    "    saliency_perturbed = saliency_fn(model, inputs_perturbed, delta)\n",
    "    \n",
    "    # Compute average absolute difference\n",
    "    avg_sens = np.mean(np.abs(saliency_orig - saliency_perturbed))\n",
    "    return avg_sens\n",
    "\n",
    "avg_sens_plain = average_sensitivity(model_plain, X_test)\n",
    "avg_sens_rich  = average_sensitivity(model_rich, X_test)\n",
    "\n",
    "print(\"Average Sensitivity (Plain):\", avg_sens_plain)\n",
    "print(\"Average Sensitivity (Richer):\", avg_sens_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec7d00-cebb-4c11-b5dc-1bc0991ca513",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Deletion Metric (Faithfulness of Saliency)\n",
    "\n",
    "The **Deletion Metric** evaluates **how faithfully the saliency map reflects the model‚Äôs true decision process**.\n",
    "\n",
    "* **Purpose:**\n",
    "  If a saliency method correctly identifies the most important features, then **removing those features should significantly reduce the model's confidence** in the true class.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Rank features for each sample by saliency (highest -> lowest importance).\n",
    "  2. Iteratively delete the top-*k* most salient features by setting them to zero.\n",
    "  3. Measure how much the model‚Äôs **true-class probability** decreases as more salient features are removed.\n",
    "  4. Repeat for *k = 1 ‚Ä¶ 5* and average across the dataset.\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * A **good saliency method** produces a **steep deletion curve** e.g. removing the ‚Äúmost important‚Äù features should sharply reduce confidence.\n",
    "  * A **flat curve** indicates that the saliency does **not** correspond to the real decision-making process.\n",
    "  * Comparing deletion curves for the **plain** vs **richer encoding** models reveals which one depends more transparently on its salient features.\n",
    "\n",
    "* **Observed Behavior (Important Insight):**\n",
    "  In our case:\n",
    "\n",
    "  * **Plain Encoding:** Confidence drops sharply from ~0.38 to 0.21 after removing the top 1‚Äì2 features, then stabilizes around ~0.30 for *k = 3‚Äì5*.\n",
    "  * **Richer Encoding:** Confidence starts higher (~0.50), drops to ~0.34 for k=2, reaches ~0.25 for k=3, then stabilizes around ~0.30 for k=4‚Äì5.\n",
    "\n",
    "  This indicates that:\n",
    "\n",
    "  * Both models rely primarily on the **top 1-2 features**.\n",
    "  * Once the key features are removed, additional deletions do **not** significantly affect confidence.\n",
    "  * The richer model‚Äôs top features are slightly more informative individually (higher initial confidence), but both models show a plateau after removing the most important features.\n",
    "\n",
    "  This is a **desirable behavior**, showing that the saliency maps faithfully identify the features most critical for the model‚Äôs predictions, and once removed, the models fall back to near-baseline confidence.\n",
    "\n",
    "* **Visualization:**\n",
    "  The plot shows:\n",
    "\n",
    "  * **x-axis:** number of removed top-salient features\n",
    "  * **y-axis:** remaining probability for the true class\n",
    "\n",
    "  A model with more faithful saliency explanations will have a **more rapidly decreasing** curve, especially in the first 1‚Äì2 feature removals, before stabilizing as the remaining features carry little additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861a32e-31aa-485f-98fe-1495888197cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletion_score(model, inputs, labels, saliency, steps=5):\n",
    "    inputs_copy = inputs.clone()\n",
    "    scores = []\n",
    "\n",
    "    for k in range(1, steps+1):\n",
    "        # Determine top-k features for each sample\n",
    "        topk = np.argsort(-saliency, axis=1)[:, :k]  # descending order\n",
    "        modified = inputs_copy.clone()\n",
    "        \n",
    "        # Zero-out top-k features\n",
    "        for i in range(modified.shape[0]):\n",
    "            modified[i, topk[i]] = 0.0\n",
    "        \n",
    "        # Get predicted probabilities for true class\n",
    "        with torch.no_grad():\n",
    "            outputs = model(modified)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            true_class_probs = probs[range(len(labels)), labels].numpy()\n",
    "        scores.append(true_class_probs.mean())\n",
    "    \n",
    "    return scores\n",
    "\n",
    "labels_test = y_test.clone().detach().long()\n",
    "deletion_plain = deletion_score(model_plain, X_test, labels_test, saliency_plain)\n",
    "deletion_rich  = deletion_score(model_rich, X_test, labels_test, saliency_rich)\n",
    "\n",
    "# Plot deletion curves\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(range(1,6), deletion_plain, marker='o', label=\"Plain\")\n",
    "plt.plot(range(1,6), deletion_rich, marker='o', label=\"Richer\")\n",
    "plt.xlabel(\"Number of Most Salient Features Removed\")\n",
    "plt.ylabel(\"Average True Class Probability\")\n",
    "plt.title(\"Deletion Metric\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac2206-1c03-4a26-bb2b-ff1c9b120fe1",
   "metadata": {},
   "source": [
    "### üß© Saliency Sparseness (Conciseness of Explanations)\n",
    "\n",
    "The **Saliency Sparseness** metric evaluates **how concentrated or distributed the saliency values are across input features**.\n",
    "\n",
    "* **Purpose:**\n",
    "  A sparse explanation highlights a **small number of highly important features**, which can improve interpretability and make explanations easier for humans to understand.\n",
    "  Conversely, a dense explanation spreads importance across many features, making it harder to discern which features truly matter.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute the **L1 norm** of the saliency map (sum of absolute values).\n",
    "  2. Compute the **L2 norm** of the saliency map (square root of sum of squares).\n",
    "  3. Define sparsity as:\n",
    "\n",
    "$$\n",
    "\\text{Sparsity} = \\frac{||\\text{saliency}||_1}{||\\text{saliency}||_2 + \\epsilon}\n",
    "$$\n",
    "\n",
    "  * Lower values indicate **higher sparsity** (more focused explanations).\n",
    "  * Higher values indicate **less sparse** explanations (spread-out feature importance).\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * **Low Sparseness** ‚Üí the model‚Äôs saliency focuses on a few key features ‚Üí easier to understand and trust.\n",
    "  * **High Sparseness** ‚Üí the model distributes importance across many features ‚Üí may indicate redundant or entangled feature use.\n",
    "  * Comparing the **plain** vs **richer encoding** models shows whether richer representations produce more concentrated or more distributed explanations. We observe that the plain encoding has a more concentrated explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54db472-919c-40fc-9473-4074654dcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_sparseness(saliency):\n",
    "    l1 = np.sum(np.abs(saliency))\n",
    "    l2 = np.sqrt(np.sum(saliency**2))\n",
    "    return l1 / (l2 + 1e-12)\n",
    "\n",
    "sparse_plain = saliency_sparseness(saliency_plain)\n",
    "sparse_rich  = saliency_sparseness(saliency_rich)\n",
    "\n",
    "print(\"Sparseness (Plain):\", sparse_plain)\n",
    "print(\"Sparseness (Rich):\", sparse_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502f031-04dd-4ad8-ab6a-4392769c8e4e",
   "metadata": {},
   "source": [
    "### üìä Saliency Entropy (Complexity of Explanations)\n",
    "\n",
    "The **Saliency Entropy** metric measures **how spread out or concentrated the feature importance is across input features**, providing a complementary view to sparsity.\n",
    "\n",
    "* **Purpose:**\n",
    "  Entropy captures the **overall complexity** of the saliency distribution:\n",
    "\n",
    "  * Low entropy ‚Üí most importance is concentrated on a few features ‚Üí simple and concise explanations\n",
    "  * High entropy ‚Üí importance is spread across many features ‚Üí more complex and potentially harder to interpret explanations\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute the **mean saliency** for each feature across all samples.\n",
    "  2. Normalize to get a probability distribution.\n",
    "  3. Compute the **Shannon entropy** of this distribution:\n",
    "\n",
    "  $$\n",
    "  H = - \\sum_i p_i \\log(p_i)\n",
    "  $$\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * **Low entropy** ‚Üí explanations are focused, highlighting a few key features.\n",
    "  * **High entropy** ‚Üí explanations are distributed, indicating the model relies on multiple features or has entangled representations.\n",
    "  * Comparing **plain** vs **richer encoding** models shows which produces simpler, more concise explanations. As we can observe, while the entropies are similar, the plain encoding produces a lower entropy and thus leading to a simpler and more concise explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914db29-9be7-4744-9c90-3b874849c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_entropy(saliency):\n",
    "    mean_sal = saliency.mean(axis=0)\n",
    "    p = mean_sal / (mean_sal.sum() + 1e-12)\n",
    "    return entropy(p)\n",
    "\n",
    "entropy_plain = saliency_entropy(saliency_plain)\n",
    "entropy_rich  = saliency_entropy(saliency_rich)\n",
    "\n",
    "print(\"Entropy (Plain):\", entropy_plain)\n",
    "print(\"Entropy (Richer):\", entropy_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e9a7a-4664-4b92-8031-6c2c6b4a0376",
   "metadata": {},
   "source": [
    "### üêû Bug Detection Signal (Saliency vs Misclassifications)\n",
    "\n",
    "The **Bug Detection Signal** evaluates **how well the saliency map differentiates between correct and incorrect predictions**, providing insight into whether the saliency highlights problematic areas when the model makes mistakes.\n",
    "\n",
    "* **Purpose:**\n",
    "  If a saliency method is faithful, **incorrect predictions should show higher saliency on features that contributed to the error**, while correct predictions should show lower saliency magnitude on misleading features. This helps identify where the model relies on the wrong cues.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute model predictions and identify **correct vs incorrect predictions**:\n",
    "  2. Compute the **average saliency magnitude** for:\n",
    "\n",
    "     * Correctly classified samples ‚Üí `sal_correct`\n",
    "     * Incorrectly classified samples ‚Üí `sal_incorrect`\n",
    "\n",
    "  3. Calculate the **ratio**:\n",
    "     * Higher ratios indicate that saliency is stronger for misclassified samples, highlighting features that may have led to errors.\n",
    "     * Low or zero ratios indicate minimal difference between correct and incorrect samples.\n",
    "\n",
    "* **Observed Behavior:**\n",
    "  Across multiple runs:\n",
    "\n",
    "  * **Plain Encoding:** Ratio is usually **0.0**, indicating that the model rarely highlights errors via its saliency ‚Äî most saliency is focused on correct predictions or the errors are minimal.\n",
    "  * **Richer Encoding:** Ratio is sometimes **0.0**, but more often a small value (~0.5), showing that the richer model‚Äôs saliency captures **features contributing to misclassifications** more reliably.\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * A **non-zero ratio** suggests the saliency map provides useful signals for debugging and understanding model mistakes.\n",
    "  * The richer encoding appears slightly **more informative for error analysis**, as its saliency better differentiates correct from incorrect predictions.\n",
    "  * The plain encoding produces mostly zero ratios, indicating less guidance for identifying problematic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaf677-6855-4d15-b0c4-5d213cf54684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_detection_signal(model, inputs, labels, saliency):\n",
    "    preds = model(inputs).argmax(dim=1).detach().cpu().numpy()\n",
    "    labels = labels if isinstance(labels, np.ndarray) else labels.detach().cpu().numpy()\n",
    "    errors = preds != labels\n",
    "\n",
    "    # Avg saliency magnitude for correct vs incorrect predictions\n",
    "    if (~errors).any():\n",
    "        sal_correct = saliency[~errors].mean()\n",
    "    else:\n",
    "        sal_correct = 0.0\n",
    "\n",
    "    if errors.any():\n",
    "        sal_incorrect = saliency[errors].mean()\n",
    "    else:\n",
    "        sal_incorrect = 0.0\n",
    "\n",
    "    ratio = sal_incorrect / (sal_correct + 1e-12)\n",
    "    \n",
    "    return {\n",
    "        \"correct_mean_saliency\": sal_correct,\n",
    "        \"incorrect_mean_saliency\": sal_incorrect,\n",
    "        \"ratio\": ratio\n",
    "    }\n",
    "\n",
    "bug_plain = bug_detection_signal(model_plain, X_test, y_test, saliency_plain)\n",
    "bug_rich  = bug_detection_signal(model_rich, X_test, y_test, saliency_rich)\n",
    "\n",
    "def print_bug_signal(name, result):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Average saliency (correct predictions)  : {result['correct_mean_saliency']:.4f}\")\n",
    "    print(f\"Average saliency (incorrect predictions): {result['incorrect_mean_saliency']:.4f}\")\n",
    "    print(f\"Ratio (incorrect / correct)             : {result['ratio']:.4f}\\n\")\n",
    "\n",
    "print_bug_signal(\"Plain Encoding\", bug_plain)\n",
    "print_bug_signal(\"Richer Encoding\", bug_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56e08c-959b-4383-b5f5-bc96f11bac70",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Overreliance Risk (Reliability of Saliency Beyond Confidence)\n",
    "\n",
    "The **Overreliance Risk** metric evaluates **whether the saliency map provides useful information beyond the model‚Äôs raw confidence**, helping to identify if users might be misled by overconfident predictions.\n",
    "\n",
    "* **Purpose:**\n",
    "  Even if a model is confident, a faithful saliency map should **highlight features that truly influence the prediction**.\n",
    "  If saliency is weakly aligned with prediction changes, users could **overtrust the model**, relying on confidence alone rather than the explanation.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute **per-sample deletion fidelity**:\n",
    "\n",
    "     * For each sample, remove the top-*k* most salient features (here *k = 1*).\n",
    "     * Measure the **drop in probability** for the true class:\n",
    "\n",
    "     $$\n",
    "     \\text{fidelity}*i = p*{\\text{true, original}} - p_{\\text{true, after deletion}}\n",
    "     $$\n",
    "\n",
    "  2. Compute the **model‚Äôs confidence** per sample:\n",
    "\n",
    "     $$\n",
    "     \\text{confidence}*i = \\max_j p*{i,j}\n",
    "     $$\n",
    "\n",
    "  3. Define **overreliance risk** as the correlation between confidence and **negative fidelity**:\n",
    "\n",
    "     $$\n",
    "     \\text{Risk} = \\text{corr}(\\text{confidence}, -\\text{fidelity})\n",
    "     $$\n",
    "\n",
    "     * A **positive correlation** ‚Üí high confidence but weak fidelity ‚Üí **high risk of misleading explanations**.\n",
    "     * A **negative or near-zero correlation** ‚Üí low risk ‚Üí saliency correctly indicates feature importance beyond mere confidence.\n",
    "\n",
    "* **Observed Behavior:**\n",
    "\n",
    "  ```\n",
    "  Overreliance Risk (Plain) : -0.168\n",
    "  Overreliance Risk (Richer): -0.164\n",
    "  ```\n",
    "\n",
    "  * Both values are slightly negative, indicating **low risk** of users being misled by overconfident predictions.\n",
    "  * The richer encoding shows similar behavior to the plain encoding, suggesting its explanations are **equally reliable** in highlighting influential features beyond model confidence.\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * Negative values ‚Üí confident predictions generally correspond to meaningful saliency drops when top features are deleted.\n",
    "  * The metric complements **Deletion Fidelity**, confirming that the saliency map is not simply reflecting the model‚Äôs raw confidence but faithfully indicates **which features truly matter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58340ae7-9754-4e9e-8b99-e6f4d69afd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletion_fidelity_per_sample(model, inputs, saliency, labels, k=1):\n",
    "    \"\"\"\n",
    "    k = how many top features to delete per sample\n",
    "    returns a vector of length N (one fidelity score per sample)\n",
    "    \"\"\"\n",
    "    N, F = inputs.shape\n",
    "\n",
    "    # base confidence for true class\n",
    "    with torch.no_grad():\n",
    "        base_probs = torch.softmax(model(inputs), dim=1)\n",
    "        base_conf = base_probs[np.arange(N), labels].cpu().numpy()\n",
    "\n",
    "    # output array\n",
    "    fidelity = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        # sort features by saliency descending\n",
    "        topk = np.argsort(-saliency[i])[:k]\n",
    "\n",
    "        # delete features\n",
    "        x_mod = inputs[i].clone()\n",
    "        x_mod[topk] = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(x_mod.unsqueeze(0))\n",
    "            prob = torch.softmax(out, dim=1)[0, labels[i]].item()\n",
    "\n",
    "        fidelity[i] = base_conf[i] - prob  # confidence drop\n",
    "    \n",
    "    return fidelity\n",
    "\n",
    "def overreliance_risk(confidence, fidelity):\n",
    "    # risk = positive correlation ‚Üí high risk of misleading confidence\n",
    "    return np.corrcoef(confidence, -fidelity)[0, 1]\n",
    "\n",
    "\n",
    "# --- Compute fidelity for both models ---\n",
    "fidelity_plain = deletion_fidelity_per_sample(model_plain, X_test, saliency_plain, y_test, k=1)\n",
    "fidelity_rich  = deletion_fidelity_per_sample(model_rich,  X_test, saliency_rich,  y_test, k=1)\n",
    "\n",
    "# --- Compute confidence per sample ---\n",
    "with torch.no_grad():\n",
    "    probs_plain = torch.softmax(model_plain(X_test), dim=1)\n",
    "    conf_plain  = probs_plain.max(dim=1).values.numpy()\n",
    "\n",
    "    probs_rich = torch.softmax(model_rich(X_test), dim=1)\n",
    "    conf_rich  = probs_rich.max(dim=1).values.numpy()\n",
    "\n",
    "# --- Compute overreliance risk ---\n",
    "risk_plain = overreliance_risk(conf_plain, fidelity_plain)\n",
    "risk_rich  = overreliance_risk(conf_rich, fidelity_rich)\n",
    "\n",
    "print(\"Overreliance Risk (Plain):\", risk_plain)\n",
    "print(\"Overreliance Risk (Rich):\",  risk_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab25c3-269f-406a-b902-1d963b7caac7",
   "metadata": {},
   "source": [
    "### üìà Minimum Efficacy (Saliency Beyond Confidence)\n",
    "\n",
    "The **Minimum Efficacy** metric evaluates **whether saliency maps provide additional explanatory power beyond the model‚Äôs raw confidence**, ensuring that explanations are meaningful even when predictions are highly confident.\n",
    "\n",
    "* **Purpose:**\n",
    "\n",
    "  * Saliency maps should highlight **which features drive predictions**, not just reflect the model‚Äôs confidence.\n",
    "  * A faithful saliency method increases **trust and interpretability**, while low or misleading efficacy could overemphasize confidence rather than true feature importance.\n",
    "\n",
    "* **Method:**\n",
    "\n",
    "  1. Compute **predictions** and a correctness vector:\n",
    "\n",
    "     * `1` ‚Üí correct prediction\n",
    "     * `0` ‚Üí incorrect prediction\n",
    "\n",
    "     ```python\n",
    "     correct = (preds == labels).astype(int)\n",
    "     ```\n",
    "\n",
    "  2. Compute **baseline confidence** per sample:\n",
    "\n",
    "     * Maximum probability assigned by the model to any class.\n",
    "\n",
    "  3. Compute **saliency signal**:\n",
    "\n",
    "     * Mean absolute saliency per sample.\n",
    "\n",
    "  4. Calculate **ROC AUC** for:\n",
    "\n",
    "     * Confidence vs correctness\n",
    "     * Saliency vs correctness\n",
    "\n",
    "  5. **Saliency Gain** = `AUC(saliency) - AUC(confidence)`\n",
    "\n",
    "     * Positive ‚Üí saliency provides additional discriminative power beyond confidence\n",
    "     * Negative ‚Üí saliency adds little or potentially misleading information\n",
    "\n",
    "* **Implementation Note:**\n",
    "\n",
    "  * If the test set contains only **one class in the correctness vector**, ROC AUC is undefined. In such cases, the metric returns `nan` instead of raising a warning.\n",
    "\n",
    "* **Observed Results:**\n",
    "\n",
    "```\n",
    "--- Plain Encoding ---\n",
    "AUC (Confidence) : nan\n",
    "AUC (Saliency)   : nan\n",
    "Saliency Gain    : nan\n",
    "\n",
    "--- Richer Encoding ---\n",
    "AUC (Confidence) : 1.0000\n",
    "AUC (Saliency)   : 0.8621\n",
    "Saliency Gain    : -0.1379\n",
    "```\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * **Plain Encoding:**\n",
    "\n",
    "    * `nan` indicates that the correctness vector contained only **one class** ‚Äî all predictions were either correct or incorrect.\n",
    "    * This is **informative about the model**: it is very consistent and confident.\n",
    "    * Since there is no variation in correctness, saliency efficacy **cannot be evaluated** via ROC AUC, but the behavior itself highlights the model‚Äôs uniform decision pattern.\n",
    "\n",
    "  * **Richer Encoding:**\n",
    "\n",
    "    * Confidence AUC = 1.0 ‚Üí the model predicts correctly with **perfect confidence**.\n",
    "    * Saliency AUC = 0.8621 ‚Üí saliency is **informative but not perfectly aligned** with correctness.\n",
    "    * Saliency Gain = -0.1379 ‚Üí saliency adds slightly less discriminative power than raw confidence alone.\n",
    "\n",
    "  * **Overall Insight:**\n",
    "\n",
    "    * Minimum Efficacy reveals **differences in both model behavior and saliency quality**.\n",
    "    * `nan` values can be **meaningful**, indicating highly consistent predictions, not just missing data.\n",
    "    * Negative saliency gain shows that even when predictions are confident, saliency maps may **underrepresent certain important features**, pointing to potential areas for improving explanation fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37453174-452c-4a58-8706-6b76e40c9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_roc_auc(y_true, y_score):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return float('nan')  # cannot compute ROC AUC\n",
    "    return roc_auc_score(y_true, y_score)\n",
    "    \n",
    "def minimum_efficacy(model, inputs, labels, saliency):\n",
    "    # predictions\n",
    "    preds = model(inputs).argmax(dim=1).cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "\n",
    "    # correctness vector: 1 = correct, 0 = wrong\n",
    "    correct = (preds == labels_np).astype(int)\n",
    "\n",
    "    # baseline confidence\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(model(inputs), dim=1).cpu().numpy()\n",
    "    conf = probs[np.arange(len(labels_np)), preds]\n",
    "\n",
    "    # saliency signal (mean absolute saliency per sample)\n",
    "    sal_signal = saliency.mean(axis=1)\n",
    "\n",
    "    # handle single-class case\n",
    "    try:\n",
    "        auc_conf = safe_roc_auc(correct, conf)\n",
    "    except ValueError:\n",
    "        auc_conf = float('nan')\n",
    "\n",
    "    try:\n",
    "        auc_sal = safe_roc_auc(correct, sal_signal)\n",
    "    except ValueError:\n",
    "        auc_sal = float('nan')\n",
    "\n",
    "    return {\n",
    "        \"auc_confidence\": auc_conf,\n",
    "        \"auc_saliency\": auc_sal,\n",
    "        \"saliency_gain\": auc_sal - auc_conf if not (np.isnan(auc_conf) or np.isnan(auc_sal)) else float('nan')\n",
    "    }\n",
    "\n",
    "# Compute minimum efficacy for both models\n",
    "min_eff_plain = minimum_efficacy(model_plain, X_test, y_test, saliency_plain)\n",
    "min_eff_rich  = minimum_efficacy(model_rich, X_test, y_test, saliency_rich)\n",
    "\n",
    "def print_min_eff(name, result):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"AUC (Confidence) : {result['auc_confidence']:.4f}\" if not np.isnan(result['auc_confidence']) else \"AUC (Confidence) : nan\")\n",
    "    print(f\"AUC (Saliency)   : {result['auc_saliency']:.4f}\"   if not np.isnan(result['auc_saliency']) else \"AUC (Saliency)   : nan\")\n",
    "    print(f\"Saliency Gain    : {result['saliency_gain']:.4f}\"   if not np.isnan(result['saliency_gain']) else \"Saliency Gain    : nan\\n\")\n",
    "\n",
    "print_min_eff(\"Plain Encoding\", min_eff_plain)\n",
    "print_min_eff(\"Richer Encoding\", min_eff_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01427f1",
   "metadata": {},
   "source": [
    "### üß† Quantum Embedding Visualization (PCA)\n",
    "\n",
    "This section visualizes the **quantum layer outputs** in 2D using **Principal Component Analysis (PCA)**:\n",
    "\n",
    "- Each point represents a test sample in the **quantum feature space**.  \n",
    "- Color corresponds to the **true class** of the sample.  \n",
    "- Comparing the two plots shows how the **plain vs richer encoding** affects the separation of classes:\n",
    "  - **Plain Encoding:** simpler mapping, possibly more overlapping clusters.  \n",
    "  - **Richer Encoding:** extra RZ rotations provide a more expressive embedding, which can lead to better class separation.  \n",
    "\n",
    "This visualization helps intuitively understand why richer encoding may improve classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent(model, name):\n",
    "    with torch.no_grad():\n",
    "        # Get quantum layer outputs for all test samples\n",
    "        latent = model.qlayer(X_test).detach().numpy()\n",
    "    \n",
    "    # Reduce dimensionality to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_2d = pca.fit_transform(latent)\n",
    "    \n",
    "    # Scatter plot: each point = one sample, colored by true class\n",
    "    plt.scatter(latent_2d[:,0], latent_2d[:,1], c=y_test, cmap='viridis')\n",
    "    plt.title(f\"Quantum Embedding (PCA) - {name}\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "# Plot side-by-side for plain vs richer encoding\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "visualize_latent(model_plain, \"Plain Encoding\")\n",
    "plt.subplot(1,2,2)\n",
    "visualize_latent(model_rich, \"Richer Encoding\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028ffdd",
   "metadata": {},
   "source": [
    "### ‚ö° Parameter Sensitivity Analysis\n",
    "\n",
    "This section evaluates how sensitive the model outputs are to changes in **each trainable parameter**:\n",
    "\n",
    "- **Gradient Magnitude:**  \n",
    "  - The gradient of the loss w.r.t. each parameter tensor is computed on the test set.  \n",
    "  - Larger gradients indicate parameters that strongly influence the model‚Äôs predictions.\n",
    "\n",
    "- **Purpose:**  \n",
    "  - Compare **plain vs richer encoding** to see how additional quantum gates affect parameter sensitivity.  \n",
    "  - Parameters with consistently higher gradients may be more important for model performance.\n",
    "\n",
    "- **Visualization:**  \n",
    "  - Each bar represents the **average absolute gradient of a full parameter tensor**, not individual weights.  \n",
    "  - The hybrid model has 5 trainable tensors:\n",
    "    1. QNN trainable parameters (theta)  \n",
    "    2. Hidden layer weights  \n",
    "    3. Hidden layer biases  \n",
    "    4. Output layer weights  \n",
    "    5. Output layer biases  \n",
    "  - Multiple bars (side-by-side) allow direct comparison between the two models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "for i, (name, mdl) in enumerate(models.items()):\n",
    "    mdl.train()  # Enable gradient computation for parameter sensitivity\n",
    "    \n",
    "    # Temporary optimizer for backward pass (not actually training)\n",
    "    optimizer = torch.optim.Adam(mdl.parameters())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass on the test set\n",
    "    outputs = mdl(X_test)\n",
    "    loss = criterion(outputs, y_test)\n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect average gradient magnitudes for each parameter\n",
    "    grads = []\n",
    "    for param in mdl.parameters():\n",
    "        if param.requires_grad and param.grad is not None:\n",
    "            grads.append(param.grad.detach().abs().mean().item())\n",
    "    \n",
    "    # Plot the average gradients for each parameter\n",
    "    plt.bar(np.arange(len(grads)) + i*0.4, grads, width=0.4, label=name)\n",
    "\n",
    "plt.xlabel(\"Parameters (theta & classical layer)\")\n",
    "plt.ylabel(\"Average Gradient Magnitude\")\n",
    "plt.title(\"Parameter Sensitivity (Gradient Proxy)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90201614",
   "metadata": {},
   "source": [
    "### üìä Wilcoxon Test: Feature Saliency Comparison\n",
    "\n",
    "This section statistically compares the **feature saliency** between the **plain** and **richer encoding** models using the **Wilcoxon signed-rank test**:\n",
    "\n",
    "- **Purpose:**  \n",
    "  - Determine whether adding richer quantum encoding significantly changes the sensitivity of the model to each input feature.\n",
    "  \n",
    "- **Procedure:**  \n",
    "  1. For each feature, extract saliency values (sensitivity) from both models.  \n",
    "  2. Apply the Wilcoxon signed-rank test to check for differences between the paired distributions.  \n",
    "  3. Mark features with `p < 0.05` as statistically significant (`*`).\n",
    "\n",
    "- **Interpretation:**  \n",
    "  - A significant result (`*`) suggests that the feature's influence on the model output differs between plain and richer encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wilcoxon Test: Plain vs Richer Encoding Feature Saliency\\n\")\n",
    "\n",
    "for feature_idx, feature_name in enumerate(iris.feature_names):\n",
    "    # Extract saliency values for the current feature for both models\n",
    "    plain_vals = saliency_plain[:, feature_idx]\n",
    "    rich_vals  = saliency_rich[:, feature_idx]\n",
    "    \n",
    "    # Perform Wilcoxon signed-rank test to compare the two distributions\n",
    "    stat, p = wilcoxon(plain_vals, rich_vals)\n",
    "    \n",
    "    # Mark statistically significant differences\n",
    "    sig = \"*\" if p < 0.05 else \"\"\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{feature_name:15}: stat={stat:.4f}, p={p:.4f} {sig}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
